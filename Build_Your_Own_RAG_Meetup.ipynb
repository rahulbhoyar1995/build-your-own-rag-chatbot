{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbC-NIgkSR9"
      },
      "source": [
        "# Build Your Own RAG using RAGStack\n",
        "This notebook shows the steps to take to use the Astra DB Vector Store as a means to make LLM interactions meaningfull and without hallucinations. The approach taken here is Retrieval Augmented Generation.\n",
        "\n",
        "You'll learn:\n",
        "1. About the content in a CNN dataset\n",
        "2. How to interact with the OpenAI Chat Model *without* providing this context\n",
        "3. How to load this context into Astra DB Vector Store\n",
        "4. How to run a semantic similarity search on Astra DB Vector Store\n",
        "5. How to use this context *with* the OpenAI Chat Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ASFNIL6IKiB"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_h_Ah_Bb_Qo",
        "outputId": "e6b3106c-b7ae-4092-b914-8858b644a426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ragstack-ai\n",
            "  Downloading ragstack_ai-0.10.0-py3-none-any.whl (4.3 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pipdeptree\n",
            "  Downloading pipdeptree-2.18.0-py3-none-any.whl (28 kB)\n",
            "Collecting astrapy<0.8.0,>=0.7.0 (from ragstack-ai)\n",
            "  Downloading astrapy-0.7.7-py3-none-any.whl (32 kB)\n",
            "Collecting cassio<0.2.0,>=0.1.3 (from ragstack-ai)\n",
            "  Downloading cassio-0.1.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.1.12 (from ragstack-ai)\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-astradb==0.1.0 (from ragstack-ai)\n",
            "  Downloading langchain_astradb-0.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting langchain-community==0.0.28 (from ragstack-ai)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.1.31 (from ragstack-ai)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai==0.0.8 (from ragstack-ai)\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Collecting llama-index[langchain]==0.9.48 (from ragstack-ai)\n",
            "  Downloading llama_index-0.9.48-py3-none-any.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-parse==0.1.4 (from ragstack-ai)\n",
            "  Downloading llama_parse-0.1.4-py3-none-any.whl (4.4 kB)\n",
            "Collecting unstructured==0.12.5 (from ragstack-ai)\n",
            "  Downloading unstructured-0.12.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading langsmith-0.1.45-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12->ragstack-ai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.1.31->ragstack-ai) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core==0.1.31->ragstack-ai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.8->ragstack-ai)\n",
            "  Downloading openai-1.17.0-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.8->ragstack-ai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.9.3 (from llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index[langchain]==0.9.48->ragstack-ai) (2023.6.0)\n",
            "Collecting httpx (from llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index[langchain]==0.9.48->ragstack-ai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index[langchain]==0.9.48->ragstack-ai) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index[langchain]==0.9.48->ragstack-ai) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index[langchain]==0.9.48->ragstack-ai) (4.10.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.5->ragstack-ai) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.5->ragstack-ai) (4.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.5->ragstack-ai) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.5->ragstack-ai) (4.12.3)\n",
            "Collecting emoji (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-iso639 (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.5->ragstack-ai) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: pip>=23.1.2 in /usr/local/lib/python3.10/dist-packages (from pipdeptree) (23.1.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai) (1.9.4)\n",
            "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from astrapy<0.8.0,>=0.7.0->ragstack-ai) (0.10.2)\n",
            "Collecting cassandra-driver>=3.28.0 (from cassio<0.2.0,>=0.1.3->ragstack-ai)\n",
            "  Downloading cassandra_driver-3.29.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12->ragstack-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12->ragstack-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12->ragstack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12->ragstack-ai) (2024.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core==0.1.31->ragstack-ai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core==0.1.31->ragstack-ai) (1.2.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver>=3.28.0->cassio<0.2.0,>=0.1.3->ragstack-ai)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12->ragstack-ai)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2<5,>=3 (from httpx->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.12->ragstack-ai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12->ragstack-ai)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m999.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index[langchain]==0.9.48->ragstack-ai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index[langchain]==0.9.48->ragstack-ai) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index[langchain]==0.9.48->ragstack-ai) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8->ragstack-ai) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.12->ragstack-ai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.12->ragstack-ai) (2.16.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.12->ragstack-ai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting pypdf>=4.0 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.12.5->ragstack-ai) (2.5)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=efa71356dbf847916be2d8495eed5e2c72ca528e988c1e6d0e2819d03f0bb466\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, dirtyjson, xxhash, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, packaging, orjson, ordered-set, mypy-extensions, langdetect, jsonpointer, jsonpath-python, hyperframe, hpack, h11, geomet, emoji, dill, deprecated, backoff, typing-inspect, tiktoken, pipdeptree, multiprocess, marshmallow, jsonpatch, httpcore, h2, deprecation, deepdiff, cassandra-driver, langsmith, httpx, dataclasses-json, cassio, unstructured-client, openai, langchain-core, datasets, unstructured, llama-index, langchain-text-splitters, langchain-openai, langchain-community, astrapy, llama-parse, langchain-astradb, langchain, ragstack-ai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed astrapy-0.7.7 backoff-2.2.1 cassandra-driver-3.29.1 cassio-0.1.5 dataclasses-json-0.6.4 datasets-2.18.0 deepdiff-7.0.1 deprecated-1.2.14 deprecation-2.1.0 dill-0.3.8 dirtyjson-1.0.8 emoji-2.11.0 filetype-1.2.0 geomet-0.2.1.post1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.12 langchain-astradb-0.1.0 langchain-community-0.0.28 langchain-core-0.1.31 langchain-openai-0.0.8 langchain-text-splitters-0.0.1 langdetect-1.0.9 langsmith-0.1.45 llama-index-0.9.48 llama-parse-0.1.4 marshmallow-3.21.1 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.17.0 ordered-set-4.1.0 orjson-3.10.0 packaging-23.2 pipdeptree-2.18.0 pypdf-4.2.0 python-dotenv-1.0.1 python-iso639-2024.2.7 python-magic-0.4.27 ragstack-ai-0.10.0 rapidfuzz-3.8.1 tiktoken-0.6.0 typing-inspect-0.9.0 unstructured-0.12.5 unstructured-client-0.22.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ragstack-ai python-dotenv pandas datasets pipdeptree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jveF3xKMZaDE"
      },
      "source": [
        "## Visualize Ragstack dependencies\n",
        "RAGStack is a curated stack of the best open-source software for easing implementation of the RAG pattern in production-ready applications using Astra Vector DB or Apache Cassandra as a vector store.\n",
        "\n",
        "A single command (pip install ragstack-ai) unlocks all the open-source packages required to build production-ready RAG applications with LangChain and the Astra Vector database.\n",
        "\n",
        "For each open-source project included in RAGStack, we select a version lineup and then test the combination for compatibility, performance, and security. Our extensive test suite ensures that RAGStack components work well together so you can confidently deploy them in production. We also run security scans on all components using industry-standard tools to ensure that you are not exposed to known vulnerabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjOp-3oMZbXn"
      },
      "outputs": [],
      "source": [
        "!pipdeptree -p ragstack-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjBB04JPIPC_"
      },
      "source": [
        "## Provide secrets for Astra DB and OpenAI\n",
        "Make sure to save your secrets somewhere safe and do not share it with anyone. Follow the below steps and provide the **Astra DB API Endpoint**, **Astra DB ApplicationToken** and **OpenAI API Key**.\n",
        "### Sign up for Astra DB\n",
        "Make sure you have a vector-capable Astra database (get one for free at [astra.datastax.com](https://astra.datastax.com))\n",
        "- You will be asked to provide the **API Endpoint** which can be found in the right pane underneath *Database details*.\n",
        "- Ensure you have an **Application Token** for your database which can be created in the right pane underneath *Database details*.\n",
        "\n",
        "### Sign up for OpenAI\n",
        "- Create an [OpenAI account](https://platform.openai.com/signup) or [sign in](https://platform.openai.com/login).\n",
        "- Navigate to the [API key page](https://platform.openai.com/account/api-keys) and create a new **Secret Key**, optionally naming the key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZjR_A2FcMvU",
        "outputId": "210de9f7-b629-4958-9c48-3149913aefd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB API Endpoint: ··········\n",
            "Your Astra DB Application Token: ··········\n",
            "Your OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "astra_endpoint = getpass('Your Astra DB API Endpoint: ')\n",
        "astra_token = getpass('Your Astra DB Application Token: ')\n",
        "openai_api_key = getpass('Your OpenAI API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4im3iS-gi0uW"
      },
      "source": [
        "## Call Open AI's Chat Model\n",
        "In this example we'll ask what Daniell Radcliffe recieves when he turns 18.\n",
        "\n",
        "As Open AI has no access to the CNN documents, it will come up with some answer that makes no sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "iOakvPOAg8rK",
        "outputId": "e59a5e84-91d6-4beb-837a-8023c0c8896c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"When Daniel Radcliffe turns 18, he receives a fortune that is not measured in material wealth or fleeting pleasures, but rather in the profound wisdom and self-awareness that comes with reaching adulthood. This fortune is akin to the Stoic philosophy of Epictetus, who believed that true wealth lies in the mastery of one's own mind and the ability to navigate life's challenges with grace and resilience.\\n\\nAs he enters this new chapter of his life, Daniel Radcliffe is gifted with the opportunity to cultivate virtues such as courage, temperance, and wisdom, much like the teachings of Aristotle. With his newfound freedom and responsibilities, he has the chance to shape his own destiny and make choices that align with his values and aspirations.\\n\\nFurthermore, turning 18 marks a significant milestone in Daniel Radcliffe's journey towards self-discovery and personal growth. It is a time for him to reflect on his past achievements and experiences, while also looking towards the future with hope and determination. This fortune grants him the chance to embrace the uncertainties of life with a sense of curiosity and openness, drawing inspiration from the existentialist philosophy of thinkers like Jean-Paul Sartre.\\n\\nIn essence, the fortune that Daniel Radcliffe receives at 18 is not one that can be measured in material terms, but rather in the richness of his inner life and the potential for growth and transformation that lies ahead. It is a fortune that invites him to embrace the complexities of the human experience and to embark on a journey of self-discovery and self-actualization, guided by the timeless wisdom of philosophical traditions that have stood the test of time.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "template = \"\"\"\n",
        "You are a philosopher that draws inspiration from great thinkers of the past\n",
        "to craft well-thought answers to user questions. Use the provided context as the basis\n",
        "for your answers and do not make up new reasoning paths - just mix-and-match what you are given.\n",
        "Your answers must be extensively written.\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "YOUR ANSWER:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", template)])\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=openai_api_key,\n",
        "    temperature=0.3,\n",
        "    model='gpt-3.5-turbo')\n",
        "\n",
        "inputs = RunnableMap({\n",
        "  'question': lambda x: x['question']\n",
        "})\n",
        "chain = inputs | prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"question\": \"What kind of fortune does Daniel Radcliffe get when he turns 18?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLbVMWq4dBDb"
      },
      "source": [
        "## Load data from CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "04f92315dc0543a099514c406e62c1a5",
            "3b41855991134da2a274def356ede94c",
            "da4e53df4a364f0db19258c2afe96abb",
            "08e3ecaedca8462386e99eef3eba3dc0",
            "5598a649cb4a45928a0f8836e13cd9fc",
            "e9305cb306a64ffe825922010b537673",
            "80b092aa458e4d3684a7ca32d018d592",
            "15cc610694344258ba5c0a765ce73002",
            "4acac7af66bd4a7daca02a095f34dda3",
            "e42c1f51deee4f96bb01123e664fb1f5",
            "375c60f1f4ff44d684b822b1b7a62464"
          ]
        },
        "id": "R-PG15Vcb6lU",
        "outputId": "8be11817-4a26-40c1-c083-5b721e8ad066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04f92315dc0543a099514c406e62c1a5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "def load_articles(n=5):\n",
        "  dataset = datasets.load_dataset('cnn_dailymail', '3.0.0', split='train', streaming=True)\n",
        "  data = dataset.take(n)\n",
        "  return [d['article']\n",
        "          for d in data]\n",
        "\n",
        "articles = load_articles()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLoGHgNVip_F"
      },
      "source": [
        "## Check out some content\n",
        "In this example we can read that when Daniel Radcliffe turns 18, he'll gain access to £20 million."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6VvIVRcv0J",
        "outputId": "84b8e3cf-1a12-49c4-d493-b9cdafac6896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n"
          ]
        }
      ],
      "source": [
        "print(articles[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-vLmRXxdE35"
      },
      "source": [
        "## Generate chunks to load into the Vector Store\n",
        "Now let's load the CNN data into the Astra DB Vector Store.\n",
        "1. First we'll chunk up the data so that it can be loaded in multiple pieces.\n",
        "2. Then we'll create a new Vector Store on Astra DB.\n",
        "3. Lastly, we'll load up the documents. As part of this step, the data will be vectorized and it's embeddings stored in the Vector Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ0XTBIFc-gU",
        "outputId": "94082f51-e9d9-4a31-c5f9-0f84f545e890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how'\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "documents = splitter.create_documents(articles)\n",
        "document_chunks = splitter.split_documents(documents)\n",
        "\n",
        "print(document_chunks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lTFsE3YdTPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1a18e216-e138-4150-f9f0-69185b570625"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRequestError",
          "evalue": "{\"errors\":[{\"message\":\"Too many collections: number of collections in database cannot exceed 5, already have 5\",\"errorCode\":\"TOO_MANY_COLLECTIONS\"}]}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/astrapy/api.py\u001b[0m in \u001b[0;36mprocess_raw_api_response\u001b[0;34m(raw_response, skip_error_check)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRequestError\u001b[0m: {\"errors\":[{\"message\":\"Too many collections: number of collections in database cannot exceed 5, already have 5\",\"errorCode\":\"TOO_MANY_COLLECTIONS\"}]}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAPIRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b311467dd51>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a new Astra DB Vector Store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m vector_store = AstraDB(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenai_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopenai_api_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"datastax\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/astradb.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embedding, collection_name, token, api_endpoint, astra_db_client, async_astra_db_client, namespace, metric, batch_size, bulk_insert_batch_concurrency, bulk_insert_overwrite_concurrency, bulk_delete_concurrency, setup_mode, pre_delete_collection)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0membedding_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_embedding_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         self.astra_env = _AstraDBCollectionEnvironment(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/utilities/astradb.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, token, api_endpoint, astra_db_client, async_astra_db_client, namespace, setup_mode, pre_delete_collection, embedding_dimension, metric)\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0;34m\"set to False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 )\n\u001b[0;32m--> 150\u001b[0;31m             self.astra_db.create_collection(\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dimension\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/astrapy/db.py\u001b[0m in \u001b[0;36mcreate_collection\u001b[0;34m(self, collection_name, options, dimension, metric)\u001b[0m\n\u001b[1;32m   2278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0;31m# Make the request to the endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m         self._request(\n\u001b[0m\u001b[1;32m   2281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{self.base_path}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/astrapy/db.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, json_data, url_params, skip_error_check)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         \u001b[0mskip_error_check\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m     ) -> API_RESPONSE:\n\u001b[0;32m-> 2170\u001b[0;31m         direct_response = api_request(\n\u001b[0m\u001b[1;32m   2171\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m             \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/astrapy/api.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(client, base_url, auth_header, token, method, json_data, url_params, path, skip_error_check, caller_name, caller_version)\u001b[0m\n\u001b[1;32m     92\u001b[0m     )\n\u001b[1;32m     93\u001b[0m     \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess_raw_api_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_error_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_error_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/astrapy/api.py\u001b[0m in \u001b[0;36mprocess_raw_api_response\u001b[0;34m(raw_response, skip_error_check)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Handle cases where json() parsing fails (e.g., empty body)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRequestError\u001b[0m: {\"errors\":[{\"message\":\"Too many collections: number of collections in database cannot exceed 5, already have 5\",\"errorCode\":\"TOO_MANY_COLLECTIONS\"}]}"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import AstraDB\n",
        "\n",
        "# Create a new Astra DB Vector Store\n",
        "vector_store = AstraDB(\n",
        "    embedding=OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
        "    collection_name=\"datastax\",\n",
        "    api_endpoint=astra_endpoint,\n",
        "    token=astra_token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "CFDN2OGMgeDi",
        "outputId": "3a98bc39-ebea-4db0-fd6b-6b6050c2a7c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vector_store' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9185aade140a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the CNN documents into the Astra DB Vector Store (Only the first time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vector_store' is not defined"
          ]
        }
      ],
      "source": [
        "# Load the CNN documents into the Astra DB Vector Store (Only the first time)\n",
        "vector_store.add_documents(document_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl7YQuwajUD2"
      },
      "source": [
        "## Run a semantic query on the Astra DB Vector Store\n",
        "Here you'll see that Astra DB retrieves relevant documents given the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtfvLocMfxkP",
        "outputId": "6b36448d-cb20-40fe-9758-3aa0c3eb1934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how'),\n",
              " Document(page_content='LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'What kind of fortune does Daniel Radcliffe get when he turns 18?'\n",
        "vector_store.similarity_search(query, k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIi6VORXjgGu"
      },
      "source": [
        "## Call OpenAI's Chat Model again\n",
        "Now let's run the query again on the OpenAI Chat Model while inserting the relevant context from the Astra DB Vector Store to make the response meaningfull and stop hallucinating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "jZdSyl1tjclO",
        "outputId": "02e48fa5-f00e-4ba7-e41c-aac62834e10e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"When Daniel Radcliffe turned 18, he gained access to a reported £20 million ($41.1 million) fortune. This substantial sum of money, accrued from his successful portrayal of Harry Potter in the film series, symbolizes not just financial security but also a significant responsibility that comes with managing such wealth. Radcliffe's newfound access to this fortune marks a transition into adulthood, where he must navigate the complexities of wealth management and societal expectations that often accompany sudden financial success.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# Get the retriever for the Chat Model\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_kwargs={\"k\": 5}\n",
        ")\n",
        "\n",
        "# Create the prompt template\n",
        "template = \"\"\"\n",
        "You are a philosopher that draws inspiration from great thinkers of the past\n",
        "to craft well-thought answers to user questions. Use the provided context as the basis\n",
        "for your answers and do not make up new reasoning paths - just mix-and-match what you are given.\n",
        "Your answers must be extensively written.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "YOUR ANSWER:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", template)])\n",
        "\n",
        "# Define the chain\n",
        "inputs = RunnableMap({\n",
        "  'context': lambda x: retriever.get_relevant_documents(x['question']),\n",
        "  'question': lambda x: x['question']\n",
        "})\n",
        "chain = inputs | prompt | llm | StrOutputParser()\n",
        "\n",
        "# Call the chain with the question\n",
        "chain.invoke({\"question\": \"What kind of fortune does Daniel Radcliffe get when he turns 18?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47pTvTWvCS4I"
      },
      "source": [
        "# Extra points 🤩 - Let's add a chat interface\n",
        "In this part of the demo, we'll actually create a fully working chatbot using Streamlit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRlnHuH9Cnzn",
        "outputId": "4c67b5f6-3e3b-4826-e864-4a309987eca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.31.1-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.9.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.31.1 validators-0.22.0 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI6ngmzAKf17"
      },
      "source": [
        "## Install the local tunnel to view the webpage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C11m15vMCwn2",
        "outputId": "a027ec8d-7b84-474d-afc6-d840d2f4a70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.033s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk4kFqDQKkuj"
      },
      "source": [
        "# Create the Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4QckPeMCYJC",
        "outputId": "5e2a24aa-ba8c-4579-fba2-3fe5b653b311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import tempfile, os\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.vectorstores import AstraDB\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Streaming call back handler for responses\n",
        "class StreamHandler(BaseCallbackHandler):\n",
        "    def __init__(self, container, initial_text=\"\"):\n",
        "        self.container = container\n",
        "        self.text = initial_text\n",
        "\n",
        "    def on_llm_new_token(self, token: str, **kwargs):\n",
        "        self.text += token\n",
        "        self.container.markdown(self.text + \"▌\")\n",
        "\n",
        "# Function for Vectorizing uploaded data into Astra DB\n",
        "def vectorize_text(uploaded_files, vector_store):\n",
        "    for uploaded_file in uploaded_files:\n",
        "        if uploaded_file is not None:\n",
        "\n",
        "            # Write to temporary file\n",
        "            temp_dir = tempfile.TemporaryDirectory()\n",
        "            file = uploaded_file\n",
        "            print(f\"\"\"Processing: {file}\"\"\")\n",
        "            temp_filepath = os.path.join(temp_dir.name, file.name)\n",
        "            with open(temp_filepath, 'wb') as f:\n",
        "                f.write(file.getvalue())\n",
        "\n",
        "            # Process TXT\n",
        "            if uploaded_file.name.endswith('txt'):\n",
        "                file = [uploaded_file.read().decode()]\n",
        "\n",
        "                text_splitter = RecursiveCharacterTextSplitter(\n",
        "                    chunk_size = 1500,\n",
        "                    chunk_overlap  = 100\n",
        "                )\n",
        "\n",
        "                texts = text_splitter.create_documents(file, [{'source': uploaded_file.name}])\n",
        "                vector_store.add_documents(texts)\n",
        "                st.info(f\"Loaded {len(texts)} chunks\")\n",
        "\n",
        "# Cache prompt for future runs\n",
        "@st.cache_data()\n",
        "def load_prompt():\n",
        "    template = \"\"\"You're a helpful AI assistent tasked to answer the user's questions.\n",
        "You're friendly and you answer extensively with multiple sentences. You prefer to use bulletpoints to summarize.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "YOUR ANSWER:\"\"\"\n",
        "    return ChatPromptTemplate.from_messages([(\"system\", template)])\n",
        "\n",
        "# Cache OpenAI Chat Model for future runs\n",
        "@st.cache_resource()\n",
        "def load_chat_model(openai_api_key):\n",
        "    return ChatOpenAI(\n",
        "        openai_api_key=openai_api_key,\n",
        "        temperature=0.3,\n",
        "        model='gpt-3.5-turbo',\n",
        "        streaming=True,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "# Cache the Astra DB Vector Store for future runs\n",
        "@st.cache_resource(show_spinner='Connecting to Astra DB Vector Store')\n",
        "def load_vector_store(_astra_db_endpoint, astra_db_secret, openai_api_key):\n",
        "    # Connect to the Vector Store\n",
        "    vector_store = AstraDB(\n",
        "        embedding=OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
        "        collection_name=\"my_store\",\n",
        "        api_endpoint=astra_db_endpoint,\n",
        "        token=astra_db_secret\n",
        "    )\n",
        "    return vector_store\n",
        "\n",
        "# Cache the Retriever for future runs\n",
        "@st.cache_resource(show_spinner='Getting retriever')\n",
        "def load_retriever(_vector_store):\n",
        "    # Get the retriever for the Chat Model\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_kwargs={\"k\": 5}\n",
        "    )\n",
        "    return retriever\n",
        "\n",
        "# Start with empty messages, stored in session state\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Draw a title and some markdown\n",
        "st.title(\"Your personal Efficiency Booster\")\n",
        "st.markdown(\"\"\"Generative AI is considered to bring the next Industrial Revolution.\n",
        "Why? Studies show a **37% efficiency boost** in day to day work activities!\"\"\")\n",
        "\n",
        "# Get the secrets\n",
        "astra_db_endpoint = st.sidebar.text_input('Astra DB Endpoint', type=\"password\")\n",
        "astra_db_secret = st.sidebar.text_input('Astra DB Secret', type=\"password\")\n",
        "openai_api_key = st.sidebar.text_input('OpenAI API Key', type=\"password\")\n",
        "\n",
        "# Draw all messages, both user and bot so far (every time the app reruns)\n",
        "for message in st.session_state.messages:\n",
        "    st.chat_message(message['role']).markdown(message['content'])\n",
        "\n",
        "# Draw the chat input box\n",
        "if not openai_api_key.startswith('sk-') or not astra_db_endpoint.startswith('https') or not astra_db_secret.startswith('AstraCS'):\n",
        "    st.warning('Please enter your Astra DB Endpoint, Astra DB Secret and Open AI API Key!', icon='⚠')\n",
        "\n",
        "else:\n",
        "    prompt = load_prompt()\n",
        "    chat_model = load_chat_model(openai_api_key)\n",
        "    vector_store = load_vector_store(astra_db_endpoint, astra_db_secret, openai_api_key)\n",
        "    retriever = load_retriever(vector_store)\n",
        "\n",
        "    # Include the upload form for new data to be Vectorized\n",
        "    with st.sidebar:\n",
        "        st.divider()\n",
        "        uploaded_file = st.file_uploader('Upload a document for additional context', type=['txt'], accept_multiple_files=True)\n",
        "        submitted = st.button('Save to Astra DB')\n",
        "        if submitted:\n",
        "            vectorize_text(uploaded_file, vector_store)\n",
        "\n",
        "    if question := st.chat_input(\"What's up?\"):\n",
        "            # Store the user's question in a session object for redrawing next time\n",
        "            st.session_state.messages.append({\"role\": \"human\", \"content\": question})\n",
        "\n",
        "            # Draw the user's question\n",
        "            with st.chat_message('human'):\n",
        "                st.markdown(question)\n",
        "\n",
        "            # UI placeholder to start filling with agent response\n",
        "            with st.chat_message('assistant'):\n",
        "                response_placeholder = st.empty()\n",
        "\n",
        "            # Generate the answer by calling OpenAI's Chat Model\n",
        "            inputs = RunnableMap({\n",
        "                'context': lambda x: retriever.get_relevant_documents(x['question']),\n",
        "                'question': lambda x: x['question']\n",
        "            })\n",
        "            chain = inputs | prompt | chat_model\n",
        "            response = chain.invoke({'question': question}, config={'callbacks': [StreamHandler(response_placeholder)]})\n",
        "            answer = response.content\n",
        "\n",
        "            # Store the bot's answer in a session object for redrawing next time\n",
        "            st.session_state.messages.append({\"role\": \"ai\", \"content\": answer})\n",
        "\n",
        "            # Write the final answer without the cursor\n",
        "            response_placeholder.markdown(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfyEfI5OKnz5"
      },
      "source": [
        "# Now run the Chatbot!\n",
        "We have to know the public URL of the server as a password.\n",
        "Once we know that, we can kick off the Streamlit app through the tunnel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07EM0gjPJscO",
        "outputId": "ddc7f703-8b28-4914-a233-0827ed86dcae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 35.225.208.37\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc15rwlIqie",
        "outputId": "5562d02e-39bd-4515-e179-eb28281faf2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.478s\n",
            "your url is: https://smooth-wombats-speak.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04f92315dc0543a099514c406e62c1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b41855991134da2a274def356ede94c",
              "IPY_MODEL_da4e53df4a364f0db19258c2afe96abb",
              "IPY_MODEL_08e3ecaedca8462386e99eef3eba3dc0"
            ],
            "layout": "IPY_MODEL_5598a649cb4a45928a0f8836e13cd9fc"
          }
        },
        "3b41855991134da2a274def356ede94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9305cb306a64ffe825922010b537673",
            "placeholder": "​",
            "style": "IPY_MODEL_80b092aa458e4d3684a7ca32d018d592",
            "value": "Downloading readme: 100%"
          }
        },
        "da4e53df4a364f0db19258c2afe96abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15cc610694344258ba5c0a765ce73002",
            "max": 15586,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4acac7af66bd4a7daca02a095f34dda3",
            "value": 15586
          }
        },
        "08e3ecaedca8462386e99eef3eba3dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42c1f51deee4f96bb01123e664fb1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_375c60f1f4ff44d684b822b1b7a62464",
            "value": " 15.6k/15.6k [00:00&lt;00:00, 230kB/s]"
          }
        },
        "5598a649cb4a45928a0f8836e13cd9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9305cb306a64ffe825922010b537673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b092aa458e4d3684a7ca32d018d592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15cc610694344258ba5c0a765ce73002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4acac7af66bd4a7daca02a095f34dda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e42c1f51deee4f96bb01123e664fb1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375c60f1f4ff44d684b822b1b7a62464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}